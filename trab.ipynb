{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "transformations = transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder('./Dataset', transform=transformations)\n",
    "\n",
    "train, test = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f'{len(trainloader)=}')\n",
    "print(f'{len(testloader)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images = next(dataiter)\n",
    "# imshow(torchvision.utils.make_grid(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(loader)\n",
    "\n",
    "def train(model, trainloader, testloader, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        print(f'Epoch: {epoch + 1} | Training Loss: {running_loss / len(trainloader):.4f} | Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "resnet.fc = nn.Linear(2048, 4)\n",
    "\n",
    "for name, params in resnet.named_parameters():\n",
    "    if name not in ('fc.weight', 'fc.bias'):\n",
    "        params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet, trainloader, testloader, optimizer, criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return (corrected / total) * 100\n",
    "\n",
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    num_classes = 4\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for true, pred in zip(labels, predicted):\n",
    "                confusion_matrix[true.item(), pred.item()] += 1\n",
    "\n",
    "    confusion_matrix = confusion_matrix.cpu().numpy()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g',\n",
    "                     xticklabels=['Bus', 'Car', 'Motorcycle', 'Truck'], yticklabels=['Bus', 'Car', 'Motorcycle', 'Truck'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, testloader)}% de acur√°cia')\n",
    "conf_mat = confusion_matrix(resnet, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return ['Bus', 'Car', 'Motorcycle', 'Truck'][result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "x = Image.open('img/ram2500.jpg').convert('RGB')\n",
    "x = transformations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet Prediction: Truck\n"
     ]
    }
   ],
   "source": [
    "print(f'Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
